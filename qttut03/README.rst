Joining forces of QRL and the Browser
=====================================


We may now link the ``Browser`` with this custom ``NetManager`` class, so we can get useful information for debugging while writing our *WebKit* apps, and boost our ``Browser`` with some additional features.

`qttut03.py 
<https://github.com/integricho/path-of-a-pyqter/blob/master/qttut03/qttut03.py>`_.

So the ``NetManager`` class became an actual subclass of ``QNetworkAccessManager`` and got renamed to ``NetworkManager``. The ``Browser`` class instantiates that new ``NetworkManager`` class instead of the default ``QNetworkAccessManager`` and binds it to it's ``QWebPage``.

We have some additional helper functions defined as well. At the very beginning we create a logger to save all the output from our application to a file, because the logging features we added produce so much output that it wouldn't fit on screen.

The ``Browser.make`` method is used to create a request, it accepts the same arguments as our ``NetManager`` class before, but under the hood it calls ``QWebView.load``. ``QWebView.load`` is an overloaded method, so it can accept either a simple url, in which case it will do a regular *GET* request, or it can accept 3 parameters: a request object (which contains a url and the request headers), a request operation (specifies the type of the request, can be: *GET*, *POST*, *PUT*,...) and the request data (the data to send in *POST* or *PUT* requests). We are using the 3 parameter solution here, and the actual request is very similarly initiated as in the previous example. We look up the request operation by the method parameter we passed to the ``Browser.make`` method, use the same urlencoder method to prepare the request data, and the same method to construct the request object as in the ``NetManager`` class.

An important difference compared to ``NetManager`` is that when we initiated a request with ``NetManager``, it made only one request. We were controlling requests there on a low level, so we loaded only the resource we wanted. With the new ``Browser`` class which uses the ``QWebView.load`` method under the hood, it won't make only one request to the target url, but in case of complex websites, there will be dozens of them automatically created by *QT*. This is because it's loading a whole webpage, so it certainly has additional resources (css/js files, images, etc.) which will cause *QT* to create new requests automatically to get them.

Our logger methods will really be on fire, but they will provide all the information you may require to discover why a page loading has failed, whether it was an SSL, network or some other type of error. These logger methods are called from the ``NetworkManager._finished`` method, which is triggered by the ``QNetworkAccessManager.finished`` signal. The reply object is passed to the ``NetworkManager._finished`` method, so we can do some inspection on it, to check whether it was successful or not. By calling the ``reply.error()`` method on the passed reply object, we check if it's return value is equal to ``QNetworkReply.NoError``, which would mean a successful request. If it's value is something else, it means that the request has failed, in which case we extract the error code and error message from it, and add it to the ``NetworkManager.errors`` list.

We use the ``NetworkManager.errors`` list to track all the errors, because when the ``loadFinished`` signal is triggered (to which we connected our ``Browser._load_finished`` method) we would be unable to check what type of error occurred (if there was any at all), so we have to look into the ``NetworkManager.errors`` list and see if it's empty or not. There are many types of errors that may occurr, some of them may simply be ignored, for instance when an image resource failed to load or something similarly unimportant, while others such as SSL errors or network errors could cause a complete page loading failure. In those cases ``QT`` always has a default value when we access the html data, it will be something like: ``<html><head></head><body></body></html>``, and if you check the error list, you will find some explanation why that happened actually.

One new feature we added here is the ability to pass an options dictionary to the ``Browser``'s ``__init__`` method, through which we specify which features of the browser we wish to use. By default we turn almost everything off, so *JavaScript*, popups, private browsing are all disabled and no images will be loaded. You may turn any of these features on, by passing a dictionary with the required key(s) and ``True`` value pair(s). If we use it for basic scraping we most certainly can turn off the automatic loading of images, which will significantly speed up the page loading, and lower the number of requests, which you can check in the log file. Turning *JavaScript* support on will most likely be required, because that's the whole point in using ``QtWebKit`` for scraping.

You may have noticed that we didn't do any kind of cleanup of *QT* objects we created until now (except for ``QNetworkReply`` objects). We didn't delete our ``QWebView``, ``QWebPage`` and ``QNetworkAccessManager``, we just called the ``QApplication.quit()`` method. This is fine with the current examples, as we are closing the application after a finished request anyway, so why bother. But imagine if it would only be part of the process our application does, suppose we are creating multiple instances of these objects at runtime, do some processing of the results, then instantiate new objects again (yes I already hear the "why would you do that?" question - well imagine we just want that). Anyway, we would be doing a really sloppy job in cleanup this way. In those cases we would have to delete these objects too, and that turns out to be trickier than one would have expected. Anyone smells a segfault? We'll get back to that topic later. Let's add some heavy weaponry to our ``Browser``...